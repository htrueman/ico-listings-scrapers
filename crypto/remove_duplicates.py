import json
import sys

import tablib

from crypto.utils import unify_title, unify_website


class RemoveDuplicateItems:
    """
    Remove matchings with old orgs list from newly arrived orgs.

    old orgs file is the file of orgs imported from pipedrive
    new orgs file should previously be generated by merge_items.py script

    """
    def __init__(self, old_orgs_file_name=None, new_orgs_file_name=None,
                 *args, **kwargs):
        self.old_orgs_file_name = old_orgs_file_name
        self.new_orgs_file_name = new_orgs_file_name

        old_orgs = tablib.Dataset().load(open(self.old_orgs_file_name).read())
        new_orgs = tablib.Dataset().load(open(self.new_orgs_file_name).read())

        self.old_orgs_json = json.loads(old_orgs.export('json'))
        self.new_orgs_json = json.loads(new_orgs.export('json'))

        self.ndo_clean_file_name = '{}_clean.json'.format(self.new_orgs_file_name.split('.')[0])

        self.main()

    def main(self):
        for new_index, new_org in enumerate(self.new_orgs_json):
            for old_index, old_org in enumerate(self.old_orgs_json):
                if unify_title(old_org['Name']).lower() == new_org['Name'].lower() \
                        or unify_website(old_org['Site']) == new_org['Address']:

                    del self.new_orgs_json[new_index]
                    del self.old_orgs_json[old_index]
                    print('Old index: ', old_index)
                    print('New index: ', new_index)
                    print('Org name: ', new_org['Name'])

        with open(self.ndo_clean_file_name, 'w+') as f:
            f.write(json.dumps(self.new_orgs_json))


if __name__ == '__main__':
    print(sys.argv[1:3])
    RemoveDuplicateItems(*sys.argv[1:3])
